{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()\n",
    "data_ctx = ctx\n",
    "model_ctx = ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(gluon.Block):\n",
    "    \n",
    "    \n",
    "    def __init__(self,user_vocabulary,user_emb_size,item_vocabulary,item_emb_size,n_hidden_layers,hidden_units,n_outputs,**kwargs):\n",
    "        \n",
    "        super(NCF,self).__init__(**kwargs)\n",
    "        \n",
    "        with self.name_scope():\n",
    "            \n",
    "            self.user_emb = gluon.nn.Embedding(input_dim=user_vocabulary+1,\n",
    "                                               output_dim=user_emb_size)\n",
    "            self.item_emb = gluon.nn.Embedding(input_dim=item_vocabulary+1,\n",
    "                                               output_dim=item_emb_size)\n",
    "\n",
    "            n_hidden_layers = n_hidden_layers\n",
    "            hidden_units = hidden_units\n",
    "            \n",
    "            if n_hidden_layers != len(hidden_units):\n",
    "                \n",
    "                raise ValueError(\"You have to specify as many hidden units as layers\")\n",
    "                \n",
    "            #for i in range(n_hidden_layers):\n",
    "                \n",
    "            #    self.__dict__[f'inner_dense_{i+1}'] = gluon.nn.Dense(units=hidden_units[i], activation='relu')\n",
    "        \n",
    "            self.dense_1 = gluon.nn.Dense(units=hidden_units[0], activation='relu')\n",
    "            self.dense_2 = gluon.nn.Dense(units=hidden_units[1], activation='relu')\n",
    "            self.out_layer = gluon.nn.Dense(units=n_outputs)\n",
    "                    \n",
    "    def forward(self, x,y):\n",
    "        \n",
    "        x = self.user_emb(x)\n",
    "        print(f\"shape of x:{x}\")\n",
    "        y = self.item_emb(y)\n",
    "        print(f\"shape of y:{y}\")\n",
    "        latent_vector = nd.concat(x,y, dim=1)\n",
    "        print(f\"shape of concatenated:{latent_vector}\")\n",
    "\n",
    "        hid = self.dense_1(latent_vector)\n",
    "        \n",
    "        out = self.out_layer(hid)\n",
    "        \n",
    "        return(out)\n",
    "                    \n",
    "        \n",
    "                    \n",
    "                    \n",
    "class MaskedSumOfSquares(gluon.loss.Loss):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        super(MaskedSumOfSquares, self).__init__(weight=None,batch_axis=0,**kwargs)\n",
    "        \n",
    "    def forward(self,output,label):\n",
    "        \n",
    "        mask = nd.greater(label,0)\n",
    "        \n",
    "        masked_output = nd.elemwise_mul(output,mask)\n",
    "        \n",
    "        return nd.sum(nd.abs(masked_output-label)**2)         \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NCF(user_vocabulary=100,user_emb_size=10,item_emb_size=10, item_vocabulary=100,n_hidden_layers=2, hidden_units=[100,200], n_outputs=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nd.array(list(range(100)))\n",
    "y = nd.array(list(range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Normal(sigma=.01), ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
